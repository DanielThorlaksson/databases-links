{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import numpy as np\n",
    "import shapely.geometry as shpg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm as colormap\n",
    "import shapely.ops\n",
    "from salem import datasets\n",
    "from cleo import Map\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the directories wherever you have unzipped your inventories and you want to have the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wgms_dir = '..\\\\WGMS\\\\DOI-WGMS-FoG-2014-09'\n",
    "rgi_dir = '..\\\\rgi50\\\\11_rgi50_CentralEurope'\n",
    "output_dir = '..\\\\WGMS_LINKS'\n",
    "f_A = os.path.join(wgms_dir, 'WGMS-FoG-2014-09-A-GENERAL-INFORMATION.csv')\n",
    "f_EE = os.path.join(wgms_dir, 'WGMS-FoG-2014-09-EE-MASS-BALANCE.csv')\n",
    "f_rgi = os.path.join(rgi_dir, '11_rgi50_CentralEurope.shp')\n",
    "f_rgi_links = '\\\\00_rgi50_links.csv'\n",
    "\n",
    "# These are the two files already produced \n",
    "f_gla = '..\\\\GLATHIDA_LINKS\\\\Manual_links_RGI_to_GlaThiDa_ALPS_20160221.csv'\n",
    "f_lec = '..\\\\LECLERCQ_LINKS\\\\Manual_links_Leclercq_to_RGI_ALPS_20160221.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wgms_dir = 'C:\\Users\\Johannes\\Documents\\OGGM\\\\WGMS\\\\DOI-WGMS-FoG-2014-09'\n",
    "rgi_dir = 'C:\\Users\\Johannes\\Documents\\OGGM\\\\rgi50\\\\11_rgi50_CentralEurope'\n",
    "output_dir = 'C:\\Users\\Johannes\\Documents\\OGGM\\\\test'\n",
    "f_A = os.path.join(wgms_dir, 'WGMS-FoG-2014-09-A-GENERAL-INFORMATION.csv')\n",
    "f_EE = os.path.join(wgms_dir, 'WGMS-FoG-2014-09-EE-MASS-BALANCE.csv')\n",
    "f_rgi = os.path.join(rgi_dir, '11_rgi50_CentralEurope.shp')\n",
    "f_rgi_links = 'C:\\Users\\Johannes\\Documents\\OGGM\\\\00_rgi50_links.csv'\n",
    "\n",
    "# These are the two files already produced  \n",
    "f_gla = 'C:\\Users\\Johannes\\Documents\\OGGM\\\\GLATHIDA_LINKS\\\\Manual_links_RGI_to_GlaThiDa_ALPS_20160221.csv'\n",
    "f_lec = 'C:\\Users\\Johannes\\Documents\\OGGM\\\\LECLERCQ_LINKS\\\\Manual_links_Leclercq_to_RGI_ALPS_20160221.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haversine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between one point \n",
    "    on the earth and an array of points (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in meters\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select WGMS IDs in the Alps by lat/lon rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lon_range = [0, 20]\n",
    "lat_range = [40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'POLITICAL_UNIT' u'NAME' u'WGMS_ID' u'RIVER_BASIN' u'FREE_POSITION'\n",
      " u'LOCAL_CODE' u'LOCAL_PSFG' u'GEN_LOCATION' u'SPEC_LOCATION' u'LATITUDE'\n",
      " u'LONGITUDE' u'PRIM_CLASSIFIC' u'FORM' u'FRONTAL_CHARS' u'EXPOS_ACC_AREA'\n",
      " u'EXPOS_ABL_AREA' u'PARENT_GLACIER' u'REMARKS' u'GEO-REGION_CODE'\n",
      " u'GEO-SUBREGION_CODE']\n"
     ]
    }
   ],
   "source": [
    "pda = pd.read_csv(f_A, encoding='iso8859_15')\n",
    "print pda.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alps_ids = pda[(pda.LONGITUDE >= lon_range[0]) & (pda.LONGITUDE <= lon_range[1]) &\n",
    "               (pda.LATITUDE >= lat_range[0]) & (pda.LATITUDE <= lat_range[1])].WGMS_ID.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select glaciers with more than 5 mass balance measurements in WGMS FoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdee = pd.read_csv(f_EE, encoding='iso8859_15')\n",
    "pdee = pdee[pdee.WGMS_ID.isin(alps_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where we have yearly measures and no altitude range\n",
    "pdee = pdee[pdee.LOWER_BOUND.isin([9999])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_id = pdee.groupby('WGMS_ID')\n",
    "ids_5 = []\n",
    "for wgmsid, group in gp_id:\n",
    "    if np.sum(np.isfinite(group.ANNUAL_BALANCE.values)) >= 5:\n",
    "        ids_5.append(wgmsid)\n",
    "len(ids_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alps_ids = ids_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the RGI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>BgnDate</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>GLIMSId</th>\n",
       "      <th>GlacType</th>\n",
       "      <th>Lmax</th>\n",
       "      <th>Name</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>RGIFlag</th>\n",
       "      <th>RGIId</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.122</td>\n",
       "      <td>334</td>\n",
       "      <td>20030799</td>\n",
       "      <td>47.4949</td>\n",
       "      <td>13.5987</td>\n",
       "      <td>20030999</td>\n",
       "      <td>G013599E47495N</td>\n",
       "      <td>0099</td>\n",
       "      <td>461</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0909</td>\n",
       "      <td>RGI50-11.00001</td>\n",
       "      <td>19.9</td>\n",
       "      <td>2338</td>\n",
       "      <td>2277</td>\n",
       "      <td>2191</td>\n",
       "      <td>POLYGON ((13.600350154 47.49330088799999, 13.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Aspect   BgnDate   CenLat   CenLon   EndDate         GLIMSId  \\\n",
       "0  0.122     334  20030799  47.4949  13.5987  20030999  G013599E47495N   \n",
       "\n",
       "  GlacType  Lmax  Name O1Region O2Region RGIFlag           RGIId  Slope  Zmax  \\\n",
       "0     0099   461  None       11        1    0909  RGI50-11.00001   19.9  2338   \n",
       "\n",
       "   Zmed  Zmin                                           geometry  \n",
       "0  2277  2191  POLYGON ((13.600350154 47.49330088799999, 13.5...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdrgi = gpd.read_file(f_rgi)\n",
    "pdrgi.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read also the GlaThiDa link file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File C:\\Users\\Johannes\\Documents\\OGGM\\GLATHIDA_LINKS\\Manual_links_RGI_to_GlaThiDa_ALPS_20160221.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-12a9c307fcf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgla_links\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_gla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgla_links\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Johannes\\Anaconda\\envs\\oggmtest\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Johannes\\Anaconda\\envs\\oggmtest\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Johannes\\Anaconda\\envs\\oggmtest\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Johannes\\Anaconda\\envs\\oggmtest\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Johannes\\Anaconda\\envs\\oggmtest\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3246)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6111)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File C:\\Users\\Johannes\\Documents\\OGGM\\GLATHIDA_LINKS\\Manual_links_RGI_to_GlaThiDa_ALPS_20160221.csv does not exist"
     ]
    }
   ],
   "source": [
    "gla_links = pd.read_csv(f_gla)\n",
    "gla_links.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read also the Leclercq link file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lec_links = pd.read_csv(f_lec)\n",
    "lec_links.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an overview plot with ALL glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr = 1  # current plot\n",
    "total = len(alps_ids)  # total number of plots ()\n",
    "\n",
    "dummyline = plt.Line2D((0,1),(0,0), color='w', linewidth=0, linestyle='')  # for dummy 'category' entry\n",
    "\n",
    "with PdfPages(os.path.join(output_dir, 'WGMS_Glaciers_Alps_ALL.pdf')) as pdf:\n",
    "    for gid in alps_ids:\n",
    "        glacier = pda[pda.WGMS_ID == gid].iloc[0]\n",
    "        lon, lat = glacier.LONGITUDE, glacier.LATITUDE\n",
    "        pdrgi['DIST'] = haversine(lon, lat, pdrgi.CenLon.values, pdrgi.CenLat.values)\n",
    "        sortrgi = pdrgi.sort(columns='DIST')\n",
    "        \n",
    "        # For GoogleMap we need a lon lat range to generate the map\n",
    "        mmlon = [lon, lon]\n",
    "        mmlat = [lat, lat]\n",
    "        \n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            # In case the glacier is a MultiPolygon we account for this here:\n",
    "            if rgig.geometry.type == 'Polygon':\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            elif rgig.geometry.type == 'MultiPolygon':\n",
    "                # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                allparts = [p.buffer(0) for p in rgig.geometry] \n",
    "                rgig.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "\n",
    "            mmlon = [np.min(np.append(mmlon, x)), np.max(np.append(mmlon, x))]\n",
    "            mmlat = [np.min(np.append(mmlat, y)), np.max(np.append(mmlat, y))]\n",
    "        \n",
    "        # Make a local map where to plot the polygons\n",
    "        local = datasets.GoogleVisibleMap(x=mmlon, y=mmlat) # also possible:  maptype='terrain'\n",
    "        local_map = Map(local.grid, countries=False, nx=640)\n",
    "        local_map.set_lonlat_countours()\n",
    "        \n",
    "        \n",
    "        # Prepare the figure\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        ax1.set_title('{}: '.format(gid) + glacier.POLITICAL_UNIT + '-' + glacier.NAME)\n",
    "        ax2.set_title(\"Smallest Haversine distance: %.2f m\" % (haversine(lon, lat, sortrgi.iloc[0].CenLon, sortrgi.iloc[0].CenLat)))\n",
    "\n",
    "        # Plot glaciers\n",
    "        colors = ['red', 'orange', 'green', 'blue', 'purple', 'magenta']\n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            # In case the glacier is a MultiPolygon we (again) account for this here:\n",
    "            if rgig.geometry.type == 'Polygon':\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            elif rgig.geometry.type == 'MultiPolygon':\n",
    "                # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                allparts = [p.buffer(0) for p in rgig.geometry] \n",
    "                rgig.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            \n",
    "            #  print centroid of matching glacier\n",
    "            if i == 0:\n",
    "                local_map.set_geometry(shpg.Point(rgig.CenLon, rgig.CenLat), edgecolor='k', marker='x', linewidth=4, markersize=100, zorder=50, text='RGI')\n",
    "            \n",
    "            # RGI polygon label\n",
    "            if rgig.Name == None:\n",
    "                plabel =  str(rgig.RGIId)+'\\n'+str(rgig.Area)+'km2'\n",
    "            else:\n",
    "                plabel =  str(rgig.RGIId)+'\\n'+str(rgig.Area)+'km2\\n'+str(rgig.Name)\n",
    "            \n",
    "            local_map.set_geometry(rgig.geometry.exterior, color=colors[i], linewidth=3, label=plabel) #adjusted for RGI 5.0\n",
    "        local_map.set_geometry(shpg.Point(rgig.CenLon, rgig.CenLat), c='k', marker='x', markersize=30, zorder=51) #again adjusted fpr RGI 5.0\n",
    "        # Plot the GlaThiDa point\n",
    "        local_map.set_geometry(shpg.Point(lon, lat), color='g', marker='x', linewidth=4, markersize=100, zorder=50, text='WGMS')\n",
    "        \n",
    "        local_map.set_rgb(local.get_vardata())\n",
    "        local_map.visualize(ax=ax1, addcbar=False)\n",
    "\n",
    "        local = datasets.GoogleVisibleMap(x=mmlon, y=mmlat, maptype='terrain')\n",
    "        local_map.set_rgb(local.get_vardata())\n",
    "        local_map.visualize(ax=ax2, addcbar=False)\n",
    "        plt.subplots_adjust(left=0.04, right=0.80, top=0.94, bottom=0.07)\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1.), fontsize=18, loc=2, borderaxespad=0, frameon=False)\n",
    "\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "        \n",
    "        if curr % 5 == 0:\n",
    "            print \"%s / %s plots done.\" % (curr, total)\n",
    "        curr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Try and automatically link WGMS IDs to all known inventories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manual_links = pda.copy()\n",
    "manual_links = manual_links[manual_links.WGMS_ID.isin(alps_ids)]\n",
    "manual_links = manual_links[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'LATITUDE', 'LONGITUDE']]\n",
    "manual_links['GlaThiDa_ID'] = np.nan\n",
    "manual_links['RGI_ID'] = np.nan\n",
    "manual_links['Leclercq_ID'] = np.nan\n",
    "manual_links['remark'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for gid in manual_links.WGMS_ID.values:\n",
    "    \n",
    "    # Link Leclercq, if possible\n",
    "    if gid in lec_links.WGMS_ID.values:\n",
    "        manual_links.Leclercq_ID[manual_links.WGMS_ID == gid] = lec_links.ID[lec_links.WGMS_ID == gid].iloc[0]\n",
    "        \n",
    "    # Use Graham to link with RGI, if possible\n",
    "    if gid in gra_links.FoGId.values:\n",
    "        manual_links.RGI_ID[manual_links.WGMS_ID == gid] = gra_links.RGIId[gra_links.FoGId == gid].iloc[0]\n",
    "    \n",
    "    # Check if some WGMS glaciers that are not in Graham's file and still need an RGI ID can be filled with Leclercq's links (which also contain RGI IDs)\n",
    "    if (not pd.isnull(manual_links.Leclercq_ID[manual_links.WGMS_ID == gid].iloc[0]) and pd.isnull(manual_links.RGI_ID[manual_links.WGMS_ID == gid].iloc[0])):\n",
    "        manual_links.RGI_ID[manual_links.WGMS_ID == gid] = lec_links.RGI_ID[lec_links.ID == manual_links.Leclercq_ID[manual_links.WGMS_ID == gid].iloc[0]].iloc[0]\n",
    "\n",
    "        \n",
    "# Link WGMS to GlaThiDa via RGI (GlaThiDa and RGi have already been linked manually)\n",
    "for rgiid in manual_links.RGI_ID.values:\n",
    "    if not pd.isnull(rgiid) and (rgiid in gla_links.RGI_equivalent.values):\n",
    "        manual_links.GlaThiDa_ID[manual_links.RGI_ID == rgiid] = gla_links.GlaThiDa_ID[gla_links.RGI_equivalent == rgiid].iloc[0]\n",
    "        \n",
    "\n",
    "manual_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manual_links.to_csv(os.path.join(output_dir, 'Automated_links_WGMS_to_RGI_GlaThiDa_Leclercq_ALPS.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
