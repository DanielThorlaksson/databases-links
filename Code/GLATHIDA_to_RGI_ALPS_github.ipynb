{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore GLATHIDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import numpy as np\n",
    "import shapely.geometry as shpg\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.ops\n",
    "from salem import datasets\n",
    "from cleo import Map\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gtd_dir = '..\\\\GlaThiDa_2014'\n",
    "rgi_dir = '..\\\\rgi50\\\\11_rgi50_CentralEurope'\n",
    "output_dir = '..\\\\GLATHIDA_LINKS'\n",
    "f_T = os.path.join(gtd_dir, 'T.csv')\n",
    "f_rgi = os.path.join(rgi_dir, '11_rgi50_CentralEurope.shp')\n",
    "corr_file = '..\\\\Manual_links_working_version_20151214.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lon_range = [0, 20]\n",
    "lat_range = [40, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between one point \n",
    "    on the earth and an array of points (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in meters\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select IDS that are candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pda = pd.read_csv(f_T, header=0, encoding='iso8859_15', sep=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove a couple of NaNs\n",
    "print(len(pda))\n",
    "pda = pda.dropna(subset=['MEAN_THICKNESS', 'AREA'])\n",
    "print(len(pda))\n",
    "all_ids = pda.GlaThiDa_ID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pda['GlaThiDa_ID'] = pda.GlaThiDa_ID.values.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alps_ids = pda[(pda.LON >= lon_range[0]) & (pda.LON <= lon_range[1]) &\n",
    "               (pda.LAT >= lat_range[0]) & (pda.LAT <= lat_range[1])].GlaThiDa_ID.values\n",
    "print len(alps_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read RGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdrgi = gpd.read_file(f_rgi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an overview plot with ALL glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "curr = 1  # current plot\n",
    "total = len(alps_ids)  # total number of plots ()\n",
    "\n",
    "\n",
    "with PdfPages(os.path.join(output_dir, 'Glathida_Glaciers_Alps_ALL.pdf')) as pdf:\n",
    "    for gid in alps_ids:\n",
    "        glacier = pda[pda.GlaThiDa_ID == gid].iloc[0]\n",
    "        lon, lat = glacier.LON, glacier.LAT\n",
    "        pdrgi['DIST'] = haversine(lon, lat, pdrgi.CenLon.values, pdrgi.CenLat.values)\n",
    "        sortrgi = pdrgi.sort(columns='DIST')\n",
    "        \n",
    "        # For GoogleMap we need a lon lat range to generate the map\n",
    "        mmlon = [lon, lon]\n",
    "        mmlat = [lat, lat]\n",
    "        \n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            # In case the glacier is a MultiPolygon we account for this here:\n",
    "            if rgig.geometry.type == 'Polygon':\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            elif rgig.geometry.type == 'MultiPolygon':\n",
    "                # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                allparts = [p.buffer(0) for p in rgig.geometry] \n",
    "                rgig.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "\n",
    "            mmlon = [np.min(np.append(mmlon, x)), np.max(np.append(mmlon, x))]\n",
    "            mmlat = [np.min(np.append(mmlat, y)), np.max(np.append(mmlat, y))]\n",
    "        \n",
    "        # Make a local map where to plot the polygons\n",
    "        local = datasets.GoogleVisibleMap(x=mmlon, y=mmlat) # also possible:  maptype='terrain'\n",
    "        local_map = Map(local.grid, countries=False, nx=640)\n",
    "        local_map.set_lonlat_countours()\n",
    "        \n",
    "        \n",
    "        # Prepare the figure\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        #ax1.set_title(glacier.GLACIER_NAME)\n",
    "        ax1.set_title('{}: '.format(gid) + glacier.POLITICAL_UNIT + '-' + glacier.GLACIER_NAME + \n",
    "                     ' {:.2f}km2'.format(glacier.AREA))\n",
    "        #ax2.set_title(\"Haversine distance: %.2f m\" % (haversine(lon, lat, lon_wgms, lat_wgms)))\n",
    "\n",
    "        # Plot glaciers\n",
    "        colors = ['red', 'orange', 'green', 'blue', 'purple', 'magenta']\n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            # In case the glacier is a MultiPolygon we (again) account for this here:\n",
    "            if rgig.geometry.type == 'Polygon':\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            elif rgig.geometry.type == 'MultiPolygon':\n",
    "                # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                allparts = [p.buffer(0) for p in rgig.geometry] \n",
    "                rgig.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            \n",
    "            #  print centroid of matching glacier\n",
    "            if i == 0:\n",
    "                local_map.set_geometry(shpg.Point(rgig.CenLon, rgig.CenLat), edgecolor='k', marker='x', linewidth=4, markersize=100, zorder=50, text='RGI')\n",
    "            \n",
    "            # RGI polygon label\n",
    "            if rgig.Name == None:\n",
    "                plabel =  str(rgig.RGIId)+'\\n'+str(rgig.Area)+'km2'\n",
    "            else:\n",
    "                plabel =  str(rgig.RGIId)+'\\n'+str(rgig.Area)+'km2\\n'+str(rgig.Name)\n",
    "            \n",
    "            local_map.set_geometry(rgig.geometry.exterior, color=colors[i], linewidth=3, label=plabel) #adjusted for RGI 5.0\n",
    "        local_map.set_geometry(shpg.Point(rgig.CenLon, rgig.CenLat), c='k', marker='x', markersize=30, zorder=51) #again adjusted fpr RGI 5.0\n",
    "        # Plot the GlaThiDa point\n",
    "        local_map.set_geometry(shpg.Point(lon, lat), color='g', marker='x', linewidth=4, markersize=100, zorder=50, text='GlaT')\n",
    "        \n",
    "        local_map.set_rgb(local.get_vardata())\n",
    "        local_map.visualize(ax=ax1, addcbar=False)\n",
    "\n",
    "        local = datasets.GoogleVisibleMap(x=mmlon, y=mmlat, maptype='terrain')\n",
    "        local_map.set_rgb(local.get_vardata())\n",
    "        local_map.visualize(ax=ax2, addcbar=False)\n",
    "        plt.subplots_adjust(left=0.04, right=0.80, top=0.94, bottom=0.07)\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1.), fontsize=18, loc=2, borderaxespad=0, frameon=False, numpoints=1,scatterpoints=1)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "        \n",
    "        if curr % 5 == 0:\n",
    "            print \"%s / %s plots done.\" % (curr, total)\n",
    "        curr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try an automated remark that checks if the found RGI polygon corresponds to the GlaThiDa glacier\n",
    "\n",
    "Check whether:\n",
    "\n",
    "+ the area of the first found RGI polygon is closer to the GlaThiDa area than the others\n",
    "+ the name of the RGI polygon (if exists) corresponds to the GlaThiDa name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pda['AutoRemark'] = np.nan\n",
    "\n",
    "for gid in alps_ids:\n",
    "        glacier = pda[pda.GlaThiDa_ID == gid].iloc[0]\n",
    "        lon, lat = glacier.LON, glacier.LAT\n",
    "        pdrgi['DIST'] = haversine(lon, lat, pdrgi.CenLon.values, pdrgi.CenLat.values)\n",
    "        sortrgi = pdrgi.sort(columns='DIST')\n",
    "        areas = []\n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            areas.append(abs(rgig.Area - glacier.AREA))\n",
    "\n",
    "        # check if absolute area difference of GlaThiDa and closest RGI polygon are closer than than differences to the\n",
    "        # second, third etc.\n",
    "        if all([x > areas[0] for x in areas[1:]]):\n",
    "            area_same = True\n",
    "        else:\n",
    "            area_same = False\n",
    "        \n",
    "        # check if names are same, if name exists in RGI\n",
    "        if rgig.Name != None:\n",
    "            #print rgig.Name, glacier.NAME\n",
    "            if rgig.Name.lower() in glacier.GLACIER_NAME.lower() or glacier.GLACIER_NAME.lower() in rgig.Name.lower():\n",
    "                name_same = True\n",
    "            else:\n",
    "                name_same = False\n",
    "        else:\n",
    "            name_same = False\n",
    "            \n",
    "        print area_same, name_same\n",
    "        \n",
    "        if area_same == True and name_same == True:\n",
    "            pda.AutoRemark[pda.GlaThiDa_ID == gid] = 'A'\n",
    "        \n",
    "        if (area_same == True and name_same == False) or (area_same == False and name_same == True):\n",
    "            pda.AutoRemark[pda.GlaThiDa_ID == gid] = 'B'\n",
    "            \n",
    "        if area_same == False and name_same == False:\n",
    "            pda.AutoRemark[pda.GlaThiDa_ID == gid] = 'C'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pda_out = pda[pda.GlaThiDa_ID.isin(alps_ids)]\n",
    "pda_out = pda_out.set_index(keys='GlaThiDa_ID')\n",
    "pda_out = pda_out[['POLITICAL_UNIT','GLACIER_NAME','SOURCE_ID','ID','LAT','LON','REMARKS','AutoRemark']]\n",
    "pda_out['ManualRemark'] = np.nan\n",
    "pda_out.to_csv('Automated_links_GlaThiDa_to_RGI_ALPS.csv', encoding='iso8859_15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the file with the manual corrections and linkings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr = pd.read_csv(corr_file)\n",
    "# select all 'safe' equivalents (\"RGI_equivalent\" is also NaN when glacier is a duplicate)\n",
    "corr_safe_equivalents = corr[~pd.isnull(corr.RGI_equivalent)]\n",
    "for gla_id in corr_safe_equivalents.GlaThiDa_ID.values:\n",
    "    corr_safe_equivalents.loc[corr_safe_equivalents['GlaThiDa_ID'] == gla_id, 'GlaThiDa_area'] = pda[pda.GlaThiDa_ID == gla_id].AREA.values[0]\n",
    "for rgi_id in corr_safe_equivalents.RGI_equivalent.values:\n",
    "    corr_safe_equivalents.loc[corr_safe_equivalents['RGI_equivalent'] == rgi_id, 'RGI_area'] = pdrgi[pdrgi.RGIId == rgi_id].Area.values[0]\n",
    "\n",
    "# select all duplicates\n",
    "corr_duplicates = corr[corr.Duplicate != 'False']\n",
    "corr_duplicates = corr_duplicates[~pd.isnull(corr_duplicates.RGI_equivalent)]\n",
    "corr_duplicates['Duplicate'] = corr_duplicates.Duplicate.values.astype(np.float64)\n",
    "\n",
    "problems = (corr[pd.isnull(corr.RGI_equivalent)])\n",
    "problems = problems[problems.Duplicate == 'False']\n",
    "len(problems)\n",
    "\n",
    "\n",
    "problems.to_csv(os.path.join(output_dir,'Problems_finding_equivalents.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(corr_safe_equivalents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out the result files for Fabien: \n",
    "\n",
    "+ One with safe linkings of GlaThiDa ID, RGI ID and only the comment (if there are duplicates, take the most recent version of GlaThiDa entry => this has been checked manually)\n",
    "+ One with RGI ID linked to all duplicates in GlaThiDa\n",
    "+ One with safe linkings of RGI area and GlaThiDa area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_safe_equivalents[['GlaThiDa_ID','GLACIER_NAME','RGI_equivalent']].to_csv(os.path.join(output_dir,'Safe_equivalents_RGI_GlaThiDa.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_duplicates = corr_duplicates[['RGI_equivalent','GlaThiDa_ID','GLACIER_NAME','Duplicate']]\n",
    "\n",
    "#print corr_safe_equivalents\n",
    "df_out = pd.DataFrame([])\n",
    "\n",
    "for dup_number in corr_duplicates.Duplicate.values:\n",
    "    try:\n",
    "        RGI_Id = corr_safe_equivalents[corr_safe_equivalents.GlaThiDa_ID == dup_number].RGI_equivalent.values[0]\n",
    "    except IndexError:\n",
    "        print 'GlaThiDa ID %s (%s) has no RGI equivalent' % (dup_number, corr_duplicates.loc[corr_duplicates.GlaThiDa_ID == dup_number, 'GLACIER_NAME'])\n",
    "        continue\n",
    "    corr_duplicates.loc[corr_duplicates['Duplicate'] == dup_number, 'RGI_equivalent'] = RGI_Id\n",
    "    \n",
    "corr_duplicates.to_csv(os.path.join(output_dir,'Duplicates_RGI_GlaThiDa.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_safe_equivalents[['GlaThiDa_ID','GLACIER_NAME','RGI_equivalent','GlaThiDa_area', 'RGI_area']].to_csv(os.path.join(output_dir,'Area_comparison_RGI_GlaThiDa.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See if these data follow a volume area scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pda = pda[pda.GlaThiDa_ID.isin(alps_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pda['VOLUME'] = pda['AREA'] * pda['MEAN_THICKNESS'] * 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pda.plot(x='AREA', y='VOLUME', kind='scatter', logx=True, logy=True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the number of duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gn = pda.groupby('GLACIER_NAME')\n",
    "duplicates = dict()\n",
    "for n, d in gn:\n",
    "    if len(d) > 1:\n",
    "        print()\n",
    "        print(d.set_index('GlaThiDa_ID')[['GLACIER_NAME', 'AREA', 'MEAN_THICKNESS', 'VOLUME', 'SURVEY_DATE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alps_ids = pda.GlaThiDa_ID.values\n",
    "alps_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all IDs, see if we find a RGI equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if GlaThiDa point is in one of the ten closest RGI polygons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_found = []\n",
    "found = dict()\n",
    "for gid in alps_ids:\n",
    "    glacier = pda[pda.GlaThiDa_ID == gid].iloc[0]\n",
    "    lon, lat = glacier.LON, glacier.LAT\n",
    "    pdrgi['DIST'] = haversine(lon, lat, pdrgi.CenLon.values, pdrgi.CenLat.values)\n",
    "    sortrgi = pdrgi.sort(columns='DIST')\n",
    "    how_long = 0\n",
    "    shpp = shpg.Point(lon, lat)\n",
    "    while True:\n",
    "        if how_long > 10:\n",
    "            not_found.append(gid)\n",
    "            break\n",
    "        if sortrgi.iloc[how_long].geometry.intersects(shpp):\n",
    "            found[gid] = sortrgi.iloc[how_long].RGIId\n",
    "            break\n",
    "        how_long += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(found), len(not_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29 glaciers could not be attributed to their ten closest RGI polygons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For those not found, no simple rule... Have a look "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those that were not found with the above method: Look whether distance to Centroid is bigger than 2000m\n",
    "# Why only 2000m?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "still_not_found = []\n",
    "final_not_found = []\n",
    "for gid in not_found:\n",
    "    glacier = pda[pda.GlaThiDa_ID == gid].iloc[0]\n",
    "    lon, lat = glacier.LON, glacier.LAT\n",
    "    pdrgi['DIST'] = haversine(lon, lat, pdrgi.CenLon.values, pdrgi.CenLat.values)\n",
    "    sortrgi = pdrgi.sort(columns='DIST')\n",
    "    if sortrgi['DIST'].iloc[0] > 2000:\n",
    "        # Extreme case\n",
    "        print(sortrgi['DIST'].iloc[0], glacier.POLITICAL_UNIT, glacier.GLACIER_NAME)\n",
    "        final_not_found.append(gid)\n",
    "    else: \n",
    "        # Keep the others for the closer look\n",
    "        still_not_found.append(gid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so for three glaciers its clear we cant do much. And what about the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pda_left = pda[pda.GlaThiDa_ID.isin(still_not_found)]\n",
    "pda_left[['POLITICAL_UNIT','GLACIER_NAME','LON','LAT', 'REMARKS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For those left they are close to shapes. Make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "curr = 1  # current plot\n",
    "total = len(still_not_found)  # total number of plots ()\n",
    "\n",
    "with PdfPages(os.path.join(output_dir, 'explore_glathida_notfound_glaciers_Alps.pdf')) as pdf:\n",
    "    for gid in still_not_found:\n",
    "        glacier = pda[pda.GlaThiDa_ID == gid].iloc[0]\n",
    "        lon, lat = glacier.LON, glacier.LAT\n",
    "        pdrgi['DIST'] = haversine(lon, lat, pdrgi.CenLon.values, pdrgi.CenLat.values)\n",
    "        sortrgi = pdrgi.sort(columns='DIST')\n",
    "        \n",
    "        # For GoogleMap we need a lon lat range to generate the map\n",
    "        mmlon = [lon, lon]\n",
    "        mmlat = [lat, lat]\n",
    "        \n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            # In case the glacier is a MultiPolygon we account for this here:\n",
    "            if rgig.geometry.type == 'Polygon':\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            elif rgig.geometry.type == 'MultiPolygon':\n",
    "                # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                allparts = [p.buffer(0) for p in rgig.geometry] \n",
    "                rgig.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "\n",
    "            mmlon = [np.min(np.append(mmlon, x)), np.max(np.append(mmlon, x))]\n",
    "            mmlat = [np.min(np.append(mmlat, y)), np.max(np.append(mmlat, y))]\n",
    "        \n",
    "        # Make a local map where to plot the polygons\n",
    "        local = datasets.GoogleVisibleMap(x=mmlon, y=mmlat) # also possible:  maptype='terrain'\n",
    "        local_map = Map(local.grid, countries=False, nx=640)\n",
    "        local_map.set_lonlat_countours()\n",
    "        \n",
    "        \n",
    "        # Prepare the figure\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        ax1.set_title(glacier.GLACIER_NAME)\n",
    "        #ax2.set_title(\"Haversine distance: %.2f m\" % (haversine(lon, lat, lon_wgms, lat_wgms)))\n",
    "\n",
    "        # Plot glaciers\n",
    "        colors = ['red', 'orange', 'green', 'blue', 'purple', 'magenta']\n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            # In case the glacier is a MultiPolygon we (again) account for this here:\n",
    "            if rgig.geometry.type == 'Polygon':\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            elif rgig.geometry.type == 'MultiPolygon':\n",
    "                # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                allparts = [p.buffer(0) for p in rgig.geometry] \n",
    "                rgig.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            \n",
    "            #  print centroid of matching glacier\n",
    "            if i == 0:\n",
    "                local_map.set_geometry(shpg.Point(rgig.CenLon, rgig.CenLat), edgecolor='k', marker='x', linewidth=4, markersize=100, zorder=50, text='RGI')\n",
    "\n",
    "            local_map.set_geometry(rgig.geometry.exterior, color=colors[i], linewidth=3, label=rgig.RGIId) #adjusted for RGI 5.0\n",
    "        local_map.set_geometry(shpg.Point(rgig.CenLon, rgig.CenLat), c='k', markersize=30, zorder=51) #again adjusted fpr RGI 5.0\n",
    "        # Plot the GlaThiDa point\n",
    "        local_map.set_geometry(shpg.Point(lon, lat), edgecolor='g', marker='x', linewidth=4, markersize=100, zorder=50, text='GlaT')\n",
    "        \n",
    "        local_map.set_rgb(local.get_vardata())\n",
    "        local_map.visualize(ax=ax1, addcbar=False)\n",
    "\n",
    "        local = datasets.GoogleVisibleMap(x=mmlon, y=mmlat, maptype='terrain')\n",
    "        local_map.set_rgb(local.get_vardata())\n",
    "        local_map.visualize(ax=ax2, addcbar=False)\n",
    "        plt.subplots_adjust(left=0.04, right=0.80, top=0.94, bottom=0.07)\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1.), fontsize=18, loc=2, borderaxespad=0, frameon=False, numpoints=1, scatterpoints=1)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "        \n",
    "        if curr % 5 == 0:\n",
    "            print \"%s / %s plots done.\" % (curr, total)\n",
    "        curr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Based on these plots and some googling, we can link some glaciers to their geometries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "still_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "links = {95:0, 108:0, 238:0, 254:0, 280:0, 289:0, 291:0, 355:0, 356:2, 497:0, 518:0, 557:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for gid in still_not_found:\n",
    "    glacier = pda[pda.GlaThiDa_ID == gid].iloc[0]\n",
    "    lon, lat = glacier.LON, glacier.LAT\n",
    "    pdrgi['DIST'] = haversine(lon, lat, pdrgi.CenLon.values, pdrgi.CenLat.values)\n",
    "    sortrgi = pdrgi.sort(columns='DIST')\n",
    "    sortrgi = sortrgi[(sortrgi.Area >= glacier.AREA/3.) & (sortrgi.Area <= glacier.AREA*3.)]\n",
    "    if gid in links:\n",
    "        found[gid] = sortrgi.iloc[links[gid]].RGIId\n",
    "    else: \n",
    "        # Keep the others for the closer look\n",
    "        final_not_found.append(gid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(found), len(final_not_found))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclude the glaciers with extreme difference in area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "odf = pd.DataFrame()\n",
    "odf['GlaThiDa_ID'] = found.keys()\n",
    "odf['RGI_ID'] = found.values()\n",
    "odf['NAME'] = [pda[pda.GlaThiDa_ID == gid].iloc[0].GLACIER_NAME for gid in found.keys()]\n",
    "odf['GTD_AREA'] = [pda[pda.GlaThiDa_ID == gid].iloc[0].AREA for gid in found.keys()]\n",
    "odf['MEAN_THICKNESS'] = [pda[pda.GlaThiDa_ID == gid].iloc[0].MEAN_THICKNESS for gid in found.keys()]\n",
    "odf['VOLUME'] = [pda[pda.GlaThiDa_ID == gid].iloc[0].VOLUME for gid in found.keys()]\n",
    "odf['SURVEY_DATE'] = [pda[pda.GlaThiDa_ID == gid].iloc[0].SURVEY_DATE for gid in found.keys()]\n",
    "odf['RGI_AREA'] = [pdrgi[pdrgi.RGIId == gid].iloc[0].Area for gid in found.values()]\n",
    "fig = plt.figure(figsize=(5, 5), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "odf.plot(x='GTD_AREA', y='RGI_AREA', kind='scatter', ax=ax);\n",
    "ax.set_xlim([0, 25]);\n",
    "ax.set_ylim([0, 25]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "odf['isclose'] =np.isclose(odf['RGI_AREA'], odf['GTD_AREA'], rtol=0.15, atol=0.4)\n",
    "fig = plt.figure(figsize=(5, 5), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "groups = odf.groupby('isclose').groups\n",
    "odf.iloc[groups[True]].plot(x='GTD_AREA', y='RGI_AREA', kind='scatter', ax=ax, color='DarkBlue', label='True');\n",
    "odf.iloc[groups[False]].plot(x='GTD_AREA', y='RGI_AREA', kind='scatter', ax=ax, color='DarkRed', label='False');\n",
    "ax.set_xlim([0, 25]);\n",
    "ax.set_ylim([0, 25]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "odf = odf.iloc[groups[True]]\n",
    "fig = plt.figure(figsize=(5, 5), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "odf.plot(x='GTD_AREA', y='RGI_AREA', kind='scatter', ax=ax);\n",
    "ax.set_xlim([0, 25]);\n",
    "ax.set_ylim([0, 25]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(odf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gn = odf.groupby('NAME')\n",
    "kept = []\n",
    "for n, d in gn:\n",
    "    if len(d) > 1:\n",
    "#         print()\n",
    "#         print(d.set_index('GlaThiDa_ID')[['NAME', 'GTD_AREA', 'RGI_AREA', 'VOLUME', 'SURVEY_DATE']])\n",
    "        subd = d.iloc[[np.argmin(np.abs(d.RGI_AREA.values - d.GTD_AREA.values))]]\n",
    "        # OK its easier to do some manually. For some glaciers we'd better take another criteria:\n",
    "        if n in ['KLEINFLEISSKEES']:\n",
    "            subd = d[d.SURVEY_DATE.isin([20049999])]\n",
    "        if n in ['SCHLADMINGER GLETSCHER']:\n",
    "            subd = d[d.SURVEY_DATE.isin([20079999])]\n",
    "        if n in ['SCHLATENKEES']:\n",
    "            subd = d[d.SURVEY_DATE.isin([20019999])]\n",
    "#         print(subd.set_index('GlaThiDa_ID')[['NAME', 'GTD_AREA', 'RGI_AREA', 'VOLUME', 'SURVEY_DATE']])\n",
    "        kept.append(subd.GlaThiDa_ID.values[0])     \n",
    "    else:\n",
    "        kept.append(d.GlaThiDa_ID.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "odf = odf[odf.GlaThiDa_ID.isin(kept)]\n",
    "len(odf), np.sum(odf.duplicated('NAME')), np.sum(odf.duplicated('RGI_ID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are still some RGI duplicates...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gn = odf.groupby('RGI_ID')\n",
    "kept = []\n",
    "for n, d in gn:\n",
    "    if len(d) > 1:\n",
    "        print()\n",
    "        print(d.set_index('GlaThiDa_ID')[['NAME', 'GTD_AREA', 'RGI_AREA', 'VOLUME', 'SURVEY_DATE']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah ok its because the names are not unique, too "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gn = odf.groupby('RGI_ID')\n",
    "kept = []\n",
    "for n, d in gn:\n",
    "    if len(d) > 1:\n",
    "        # Simply take the newest\n",
    "        d = d.iloc[[np.argmax(d.SURVEY_DATE.values)]]\n",
    "#         print()\n",
    "#         print(d.set_index('GlaThiDa_ID')[['NAME', 'GTD_AREA', 'RGI_AREA', 'VOLUME', 'SURVEY_DATE']])\n",
    "        kept.append(d.GlaThiDa_ID.values[0])\n",
    "    else:\n",
    "        kept.append(d.GlaThiDa_ID.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "odf = odf[odf.GlaThiDa_ID.isin(kept)]\n",
    "len(odf), np.sum(odf.duplicated('NAME')), np.sum(odf.duplicated('RGI_ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odf = odf.set_index('GlaThiDa_ID').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final plot of found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "curr = 1  # current plot\n",
    "total = len(odf.index.values)  # total number of plots ()\n",
    "\n",
    "with PdfPages(os.path.join(output_dir, 'final_glathida_glaciers_found.pdf')) as pdf:\n",
    "    for gid, rgiid in zip(odf.index.values, odf.RGI_ID.values):\n",
    "        glacier = pda[pda.GlaThiDa_ID == gid].iloc[0]\n",
    "        lon, lat = glacier.LON, glacier.LAT\n",
    "        pdrgi['DIST'] = haversine(lon, lat, pdrgi.CenLon.values, pdrgi.CenLat.values)\n",
    "        sortrgi = pdrgi.sort(columns='DIST')\n",
    "        \n",
    "        # For GoogleMap we need a lon lat range to generate the map\n",
    "        mmlon = [lon, lon]\n",
    "        mmlat = [lat, lat]\n",
    "        \n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            # In case the glacier is a MultiPolygon we account for this here:\n",
    "            if rgig.geometry.type == 'Polygon':\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            elif rgig.geometry.type == 'MultiPolygon':\n",
    "                # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                allparts = [p.buffer(0) for p in rgig.geometry] \n",
    "                rgig.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "\n",
    "            mmlon = [np.min(np.append(mmlon, x)), np.max(np.append(mmlon, x))]\n",
    "            mmlat = [np.min(np.append(mmlat, y)), np.max(np.append(mmlat, y))]\n",
    "            \n",
    "        # Prepare the figure\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        ax1.set_title('{}: '.format(gid) + glacier.POLITICAL_UNIT + '-' + glacier.GLACIER_NAME + \n",
    "                     ' {:.2f}km2'.format(glacier.AREA))\n",
    "        \n",
    "        local = datasets.GoogleVisibleMap(x=mmlon, y=mmlat) \n",
    "        local_map = Map(local.grid, countries=False, nx=640)\n",
    "        local_map.set_lonlat_countours()\n",
    "\n",
    "            \n",
    "        # Plot glaciers\n",
    "        colors = ['red', 'orange', 'green', 'blue', 'purple', 'magenta']\n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            # In case the glacier is a MultiPolygon we (again) account for this here:\n",
    "            if rgig.geometry.type == 'Polygon':\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            elif rgig.geometry.type == 'MultiPolygon':\n",
    "                # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                allparts = [p.buffer(0) for p in rgig.geometry] \n",
    "                rgig.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            \n",
    "            #  print centroid of matching glacier\n",
    "            if i == 0:\n",
    "                local_map.set_geometry(shpg.Point(rgig.CenLon, rgig.CenLat), edgecolor='k', marker='x', linewidth=4, markersize=100, zorder=50, text='matching')\n",
    "            \n",
    "            px, py = rgig.CenLon, rgig.CenLat \n",
    "            local_map.set_geometry(shpg.Point(px, py), markersize=6, linewidth=0, color='black') \n",
    "            local_map.set_geometry(rgig.geometry.exterior, color=colors[i], linewidth=3, label=rgig.RGIId) \n",
    "            \n",
    "        # Plot selected glacier\n",
    "        rgig = pdrgi[pdrgi.RGIId == rgiid].iloc[0]\n",
    "        px, py = rgig.CenLon, rgig.CenLat \n",
    "        local_map.set_geometry(shpg.Point(px, py), marker='x', markersize=6, linewidth=0, color='red')\n",
    "\n",
    "        # Plot the point\n",
    "        px, py = lon, lat #local.transform(lon, lat)\n",
    "        local_map.set_geometry(shpg.Point(px, py), marker='o', markersize=7, linewidth=0, color='red')\n",
    "        \n",
    "        local_map.set_rgb(local.get_vardata())\n",
    "        local_map.visualize(ax=ax1, addcbar=False)\n",
    "\n",
    "        local = datasets.GoogleVisibleMap(x=mmlon, y=mmlat, maptype='terrain')\n",
    "        local_map.set_rgb(local.get_vardata())\n",
    "        local_map.visualize(ax=ax2, addcbar=False)\n",
    "        plt.subplots_adjust(left=0.04, right=0.80, top=0.94, bottom=0.07)\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1.), fontsize=18, loc=2, borderaxespad=0, frameon=False, numpoints=1,\n",
    "                       scatterpoints=1)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "        \n",
    "        if curr % 5 == 0:\n",
    "            print \"%s / %s plots done.\" % (curr, total)\n",
    "        curr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Final plot of not found "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really usfull because there are the duplicates and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "curr = 1  # current plot\n",
    "total = len(set(all_ids) - set(odf.index.values))  # total number of plots ()\n",
    "\n",
    "with PdfPages(os.path.join(output_dir, 'final_glathida_glaciers_not_found.pdf')) as pdf:\n",
    "    for gid in all_ids:\n",
    "        if gid in odf.index.values:\n",
    "            continue\n",
    "            \n",
    "        glacier = pda[pda.GlaThiDa_ID == gid].iloc[0]\n",
    "        lon, lat = glacier.LON, glacier.LAT\n",
    "        pdrgi['DIST'] = haversine(lon, lat, pdrgi.CenLon.values, pdrgi.CenLat.values)\n",
    "        sortrgi = pdrgi.sort(columns='DIST')\n",
    "        \n",
    "        # For GoogleMap we need a lon lat range to generate the map\n",
    "        mmlon = [lon, lon]\n",
    "        mmlat = [lat, lat]\n",
    "        \n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            # In case the glacier is a MultiPolygon we account for this here:\n",
    "            if rgig.geometry.type == 'Polygon':\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            elif rgig.geometry.type == 'MultiPolygon':\n",
    "                # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                allparts = [p.buffer(0) for p in rgig.geometry] \n",
    "                rgig.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "\n",
    "            mmlon = [np.min(np.append(mmlon, x)), np.max(np.append(mmlon, x))]\n",
    "            mmlat = [np.min(np.append(mmlat, y)), np.max(np.append(mmlat, y))]\n",
    "        \n",
    "        # Make a local map where to plot the polygons\n",
    "        local = datasets.GoogleVisibleMap(x=mmlon, y=mmlat) # also possible:  maptype='terrain'\n",
    "        local_map = Map(local.grid, countries=False, nx=640)\n",
    "        local_map.set_lonlat_countours()\n",
    "        \n",
    "        \n",
    "        # Prepare the figure\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        ax1.set_title(glacier.GLACIER_NAME)\n",
    "        #ax2.set_title(\"Haversine distance: %.2f m\" % (haversine(lon, lat, lon_wgms, lat_wgms)))\n",
    "\n",
    "        # Plot glaciers\n",
    "        colors = ['red', 'orange', 'green', 'blue', 'purple', 'magenta']\n",
    "        for i in np.arange(0,5):\n",
    "            rgig = sortrgi.iloc[i]\n",
    "            # In case the glacier is a MultiPolygon we (again) account for this here:\n",
    "            if rgig.geometry.type == 'Polygon':\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            elif rgig.geometry.type == 'MultiPolygon':\n",
    "                # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                allparts = [p.buffer(0) for p in rgig.geometry] \n",
    "                rgig.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                x, y = rgig.geometry.exterior.xy\n",
    "            \n",
    "            #  print centroid of matching glacier\n",
    "            if i == 0:\n",
    "                local_map.set_geometry(shpg.Point(rgig.CenLon, rgig.CenLat), edgecolor='k', marker='x', linewidth=4, markersize=100, zorder=50, text='RGI')\n",
    "\n",
    "            local_map.set_geometry(rgig.geometry.exterior, color=colors[i], linewidth=3, label=rgig.RGIId) #adjusted for RGI 5.0\n",
    "        local_map.set_geometry(shpg.Point(rgig.CenLon, rgig.CenLat), c='k', markersize=30, zorder=51) #again adjusted fpr RGI 5.0\n",
    "        # Plot the GlaThiDa point\n",
    "        local_map.set_geometry(shpg.Point(lon, lat), edgecolor='g', marker='x', linewidth=4, markersize=100, zorder=50, text='GlaT')\n",
    "        \n",
    "        local_map.set_rgb(local.get_vardata())\n",
    "        local_map.visualize(ax=ax1, addcbar=False)\n",
    "\n",
    "        local = datasets.GoogleVisibleMap(x=mmlon, y=mmlat, maptype='terrain')\n",
    "        local_map.set_rgb(local.get_vardata())\n",
    "        local_map.visualize(ax=ax2, addcbar=False)\n",
    "        plt.subplots_adjust(left=0.04, right=0.80, top=0.94, bottom=0.07)\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1.), fontsize=18, loc=2, borderaxespad=0, frameon=False, numpoints=1,\n",
    "                       scatterpoints=1)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "        \n",
    "        if curr % 5 == 0:\n",
    "            print \"%s / %s plots done.\" % (curr, total)\n",
    "        curr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odf.to_csv(os.path.join(output_dir, 'GLATHIDA_to_RGI_Alps.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
